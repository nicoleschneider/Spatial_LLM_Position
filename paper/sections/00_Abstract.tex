\nrscomment{shift focus to thoroughly evaluating across all relation types}

In this paper we present the challenges and opportunities associated with using large language models (LLMs) for spatial reasoning.
We demonstrate that despite recent work indicating that LLMs possess some level of geospatial awareness, there are significant shortcomings as the complexity of the spatial prompts increases even slightly.

\nrscomment{describe experiments and interesting findings}

We describe several embedding techniques and ideas for self-supervised training objectives that may address these shortcomings and enable LLMs to more effectively learn to reason over spatial data.
Finally, we discuss longer term opportunities with multimodal learning that may ultimately enable the design of a general geo foundation model that can perform spatial reasoning over a variety of sources and scales of geospatial data.


