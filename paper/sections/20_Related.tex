\section{Related Work}
\label{section:related}
\normalsize

Many recent works have explored the abilities and limitations of LLMs for performing various reasoning tasks, from math word problems~\cite{Gao2023, Badaro2023} to place name resolution \cite{Mai2024}.
In this section we summarize the recent work investigating the degree to which LLMs can reason spatially.
We describe recent work probing LLMs for spatial and geographic knowledge, papers on geo-foundation models, and papers proposing techniques that enable LLMs to answer spatial questions.

\subsection{Spatial and Geographic Knowledge in LLMs}
A few recent works have probed to what degree LLMs like ChatGPT can answer questions involving spatial components.
\citeauthor{Mooney2023} reveal limitations in ChatGPT's fundamental GIS knowledge by prompting it with multiple choice questions from a GIS exam~\cite{Mooney2023}.
\citeauthor{Bang2023}~\cite{Bang2023} shows that ChatGPT is unreliable at general reasoning tasks, and
\citeauthor{Cohn2023}~\cite{Cohn2023} shows that it fails at generic (non-geographic) spatial reasoning questions like whether a larger circle be contained inside a smaller one.
In more task-oriented exploration, 
\citeauthor{Xie2023translating} shows that LLMs perform poorly at planning on tasks that involve spatial reasoning, including moving objects around for robotics applications~\cite{Xie2023translating}.
Similarly, 
\citeauthor{Tao2023} find faults in map visualizations and sketch maps generated by ChatGPT using code or ASCII symbols~\cite{Tao2023}.
These findings collectively reveal potential issues in the fundamental reasoning and geographic knowledge of LLMs, which we extend by evaluating geospatial reasoning across all the major spatial relation types for many different LLMs.

\subsection{Geo-foundation Models}
Recent vision papers suggest that LLMs show promise for use as geospatial databases, where the LLM performs spatial reasoning given natural language prompts~\cite{Bhandari2023, Qi2023}.
\citeauthor{Bhandari2023}~\cite{Bhandari2023} and \citeauthor{Qi2023}~\cite{Qi2023} support their visions with experiments prompting LLMs for geocoordinates of popular cities, with results showing promisingly accurate coordinates for most of the cities tested.
\citeauthor{Bhandari2023} further prompt the LLMs to generate names of cities that are ``near'' or ``far'' from a provided reference city.
They show that the resulting cities generated tend to be closer in distance to the reference point when the ``near'' prompt is used, and farther when the ``far'' prompt is used, indicating LLMs are capable of basic spatial reasoning in that they associate distance meaning to those keywords.
However, other work has shown that LLMs lack the ability to adapt the meaning of those keywords to the scale relevant to the question asked, when provided with reference points indicating what `near' or `far' means in a given context~\cite{Osullivan2024}.
RAG has been shown to improve distance-based reasoning in LLMs using techniques like DistRAG~\cite{} \nrscomment{cite DistRAG and journal}, but no previous work has explored distance-invariant spatial reasoning, like topological or directional reasoning between geoentities, to our knowledge.
% Our paper presents a similar position, that LLMs have potential to perform spatial reasoning, but our experiments show that much more work is needed before this vision can be realized.
% We show that LLMs currently cannot handle many of the intricacies of spatial reasoning beyond the simple pairwise directional relationships between locations tested by \citeauthor{Bhandari2023} and \citeauthor{Qi2023}.

\subsection{LLM Adaptations for Geodata}
Several embedding methods and model architectures have been proposed to enable LLMs to handle certain types of geospatial data.
For trajectories of geocoordinates, \citeauthor{Hu2023} propose an embedding method that uses sub-trajectory similarity learning to pre-train trajectory representations that can be used in downstream prediction tasks~\cite{Hu2023}.
For textual georeferences, \citeauthor{Li2021} design a pre-training task using spatial coordinate embeddings %(based on latitude and longitude) 
corresponding to textual georeferences, which improve
% They create pseudosentences consisting of a geoentity reference and neighboring entities, listed in increasing order of distance from the reference entity~\cite{Li2021}.
accuracy over non-spatial methods on geoentity type prediction and linking to knowledge graphs~\cite{Li2021}.
\citeauthor{Li2023b} design a contrastive learning method, GeoLM, that performs toponym recognition and linking, geoentity typing, and geospatial relation extraction~\cite{Li2023b}.
% However, to ensure applicability to a variety of tasks, there remains a need for more intuitive self-supervised tasks to train spatial coordinate embeddings.
For spatio-temporal forecasting, \citeauthor{Liu2024large} propose a method of tokenization and encoding to increase LLM understanding of spatio-temporal text references~\cite{Liu2024large}.
% While significant headway has been made recently in embedding geodata, there remains a lack of self-supervised training objectives pertaining to geospatial reasoning, which we discuss further in section \ref{section:future}.

Some other benchmarks and new methods have also been proposed to advance LLM performance on geospatial tasks, but the majority of these focus on a few specific types of spatial tasks, like
factoid-based or population variable prediction questions~\cite{Qi2023,Roberts2023,Gupta2024,Yan2024,Manvi2024,Lietard2021}, 
trajectory prediction or POI and itinerary recommendation tasks~\cite{Schneider2025,Yu2025,Roberts2023,Xie2024,Gundawar2024,De2024,Sharma2023}, 
distance-based reasoning questions~\cite{Bhandari2023,Osullivan2024} \nrscomment{cite DistRAG and journal}, 
or visual tasks like geo-localization, geographic visualization, and traffic signal control~\cite{Feng2024b,Chen2024}.
None of these methods explicitly address topological, directional, or cyclic order relations over geographic entities, though some downstream questions inherently require reasoning over these relationships.
Examples include \citeauthor{Li2024} which address the StepGame Benchmark for directional reasoning over fictional entities labeled with letters in a scene~\cite{Li2024} and \citeauthor{Majic2024} which evaluate a brick stacking task~\cite{Majic2024}.

By showing how base LLMs and RAG variants perform on explicit spatial reasoning questions we reveal \nrscomment{what is finding}.
 

% For example, we suggest crafting natural language descriptions of the spatial relationships between neighboring entities rather than listing them, which would more closely align the task with the unstructured text prediction tasks typically used to train LLMs.

% For modeling complex multi-way spatial relationships like those needed for spatial pattern matching, graphs are typically used to encode the data~\cite{Folkers2000, Chen2019, Fang2019}.
% To train neural models like Graph Neural Networks (GNNs) on graph-encoded data, node-level and edge-level embeddings are commonly used~\cite{Bai2019,Krlevza2016,Liu2020Neural}.


%------NEXT Paper-------------
% For structured tabular data, training general purpose transformer-based foundation models that can handle tabular inputs is an active area of research~\cite{Cong2023, Badaro2023, Iida2021, Somepalli2022, Seng2022, Yin2020, Herzig2020}.



%\nrscomment{describe the embeddings and explain how pretraining task would differ}
%\cite{Iida2021, Somepalli2022, Seng2022, Yin2020, Herzig2020}

% \subsubsection{Model Architectures}
% For RSI, spatial heterogeneity prevents the standard vision methods from working out of the box. 
% \cite{Xie2021} adapts the model architecture through a series of statistical tests to address the different spatial distributions present in the data.
% \nrscomment{can we handle it in the embeddings instead?}

% \nrscomment{other related work that proposes novel architectures?}


% \subsection{NL to Spatial Query}
%     NALSpatial: \cite{Liu2023}


% \subsection{Testing LLM Spatial Reasoning}
%     \cite{Bhandari2023} shows some degree of near/far but not true complex spatial reasoning
%     MaaSDB: \cite{Qi2023} shows some ability to do pairwise directional relations for well-known cities

% \subsection{Large Language Models as Databases}
%     \paragraph{As generic DBs}
%         \cite{Tan2023}
        
%         James Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio Silvestri, Sebastian Riedel, and Alon Halevy. 2021. From Natural Language Processing to Neural Databases. PVLDB (2021)
        
%         \cite{Trappolini2023}
        
%     \paragraph{As spatial DBs}
%         Ref ideas of MaaSDB