\section{Related Work}
\label{section:related}
\normalsize

Many recent works have explored the abilities and limitations of LLMs for performing various reasoning tasks, from math word problems~\cite{Gao2023, Badaro2023} to place name resolution \cite{Mai2023}.
In this section we summarize the recent work investigating the degree to which LLMs can reason spatially.
We begin by describing recent work probing LLMs for spatial and geographic knowledge, then survey recent papers on geo-foundation models, and finally discuss specific techniques proposed to enable LLMs to ingest and reason over spatial data.


\subsection{General Spatial and Geographic Knowledge in LLMs}
A few recent works have probed to what degree LLMs like ChatGPT can answer questions involving spatial components.
%
\citeauthor{Mooney2023} reveal limitations in ChatGPT's fundamental GIS knowledge by prompting it with multiple choice questions from a GIS exam~\cite{Mooney2023}.
\citeauthor{Bang2023}~\cite{Bang2023} shows that ChatGPT is unreliable at general reasoning tasks, and
\citeauthor{Cohn2023}~\cite{Cohn2023} shows that it fails at generic (non-geographic) spatial reasoning questions like whether a larger circle be contained inside a smaller one.
In more task-oriented exploration, 
\citeauthor{Xie2023translating}~\cite{Xie2023translating} shows that LLMs perform poorly at planning on tasks that involve spatial reasoning, including moving objects around for robotics applications.
Similarly, 
\citeauthor{Tao2023}~\cite{Tao2023} find faults in map visualizations and sketch maps generated by ChatGPT using code or ASCII symbols.
%
These findings collectively reveal potential issues in the fundamental reasoning and geographic knowledge of LLMs.

\nrscomment{relate back to our findings/contribution}




\subsection{Geospatial LLMs and Geo-foundation Models}
Two recent vision papers suggest that LLMs show promise for use as geospatial databases, where the LLM performs spatial reasoning given natural language prompts~\cite{Bhandari2023, Qi2023}.
\citeauthor{Bhandari2023}~\cite{Bhandari2023} and \citeauthor{Qi2023}~\cite{Qi2023} support their visions with experiments prompting LLMs for geocoordinates of popular cities, with results showing promisingly accurate coordinates for most of the cities tested.
\citeauthor{Bhandari2023} further prompt the LLMs to generate names of cities that are ``near'' or ``far'' from a provided reference city.
They show that the resulting cities generated tend to be closer in distance to the reference point when the ``near'' prompt is used, and farther when the ``far'' prompt is used, indicating LLMs are capable of basic spatial reasoning in that they associate metric (distance) meaning to those keywords.
%
\nrscomment{update rest of paragraph in relation to our work once we have results}
%
Our paper presents a similar position, that LLMs have potential to perform spatial reasoning, but our experiments show that much more work is needed before this vision can be realized.
We show that LLMs currently cannot handle many of the intricacies of spatial reasoning beyond the simple pairwise directional relationships between locations tested by \citeauthor{Bhandari2023} and \citeauthor{Qi2023}.

\citeauthor{Mai2023} present a vision of a geo foundation model pre-trained on different modalities of data, aligning their representations based on location information~\cite{Mai2023}.
Likewise, \citeauthor{Fei2022} propose a generic foundation model for human mobility data, a form of spatial data, at various scales~\cite{Fei2022}.
%
\nrscomment{update rest of paragraph in relation to our work once we have results}
%
We similarly envisage a geo-foundation model that can handle many input modalities and scales, but we identify challenges associated with designing embeddings, model architectures, and self-supervised tasks that must first be addressed for individual types of geodata, before they can be combined in a multimodal geo foundation model.
%\cite{Mai2023} - focuses on need for multimodal and claims some text based geo tasks like toponym recognition are already well-solved by existing LLMs.

Other vision papers highlight the challenges and opportunities associated with combining structured and unstructured geodata to create a geo foundation model, but they do not propose any concrete steps to achieve such a goal~\cite{Xie2023, Tan2023}.

\nrscomment{update if relevant or not to our contribution/findings}




\subsection{LLM Adaptations for Geodata}
A few embedding methods and model architectures have been proposed to enable LLMs to handle certain types of geospatial data.
%
For trajectories of geocoordinates, \citeauthor{Hu2023} propose an embedding method that uses sub-trajectory similarity learning to pre-train trajectory representations that can be used in downstream prediction tasks~\cite{Hu2023}.
%
For textual georeferences, \citeauthor{Li2021} design a pre-training task using spatial coordinate embeddings (based on latitude and longitude) corresponding to textual georeferences, which improve
% They create pseudosentences consisting of a geoentity reference and neighboring entities, listed in increasing order of distance from the reference entity~\cite{Li2021}.
 accuracy over non-spatial methods on the downstream tasks of geoentity type prediction and linking to knowledge graphs~\cite{Li2021}.
% However, to ensure applicability to a variety of tasks, there remains a need for more intuitive self-supervised tasks to train spatial coordinate embeddings.
For spatio-temporal forecasting, \citeauthor{Liu2024large} propose a method of tokenization and encoding to increase LLM understanding of spatio-temporal text references~\cite{Liu2024large}.

\nrscomment{update with tie to our contribution/findings}




 



% For example, we suggest crafting natural language descriptions of the spatial relationships between neighboring entities rather than listing them, which would more closely align the task with the unstructured text prediction tasks typically used to train LLMs.

% For modeling complex multi-way spatial relationships like those needed for spatial pattern matching, graphs are typically used to encode the data~\cite{Folkers2000, Chen2019, Fang2019}.
% To train neural models like Graph Neural Networks (GNNs) on graph-encoded data, node-level and edge-level embeddings are commonly used~\cite{Bai2019,Krlevza2016,Liu2020Neural}.


%------NEXT Paper-------------
% For structured tabular data, training general purpose transformer-based foundation models that can handle tabular inputs is an active area of research~\cite{Cong2023, Badaro2023, Iida2021, Somepalli2022, Seng2022, Yin2020, Herzig2020}.



%\nrscomment{describe the embeddings and explain how pretraining task would differ}
%\cite{Iida2021, Somepalli2022, Seng2022, Yin2020, Herzig2020}

% \subsubsection{Model Architectures}
% For RSI, spatial heterogeneity prevents the standard vision methods from working out of the box. 
% \cite{Xie2021} adapts the model architecture through a series of statistical tests to address the different spatial distributions present in the data.
% \nrscomment{can we handle it in the embeddings instead?}

% \nrscomment{other related work that proposes novel architectures?}


% \subsection{NL to Spatial Query}
%     NALSpatial: \cite{Liu2023}


% \subsection{Testing LLM Spatial Reasoning}
%     \cite{Bhandari2023} shows some degree of near/far but not true complex spatial reasoning
%     MaaSDB: \cite{Qi2023} shows some ability to do pairwise directional relations for well-known cities

% \subsection{Large Language Models as Databases}
%     \paragraph{As generic DBs}
%         \cite{Tan2023}
        
%         James Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio Silvestri, Sebastian Riedel, and Alon Halevy. 2021. From Natural Language Processing to Neural Databases. PVLDB (2021)
        
%         \cite{Trappolini2023}
        
%     \paragraph{As spatial DBs}
%         Ref ideas of MaaSDB