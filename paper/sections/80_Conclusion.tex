\section{Conclusion}
\label{section:conclusion}
\normalsize


Recent work has demonstrated that LLMs have some level of spatial awareness in the form of knowledge about geocoordinates, directional relationships between major cities, and relative distances between cities.
We develop a series of experiments designed to cover a broad range of spatial tasks that have received less attention, namely directional, topological, and cyclic order relations, and show that increasing the complexity of the tasks by even one additional entity greatly reduces spatial reasoning performance in the LLMs we tested.
By revealing significant gaps in the spatial reasoning abilities of current LLMs, we motivate the need for additional work in developing new embedding techniques and self-supervised learning objectives for geospatial reasoning tasks, paving the way for future geo-foundation models that can reason about a variety of spatial relationships.



%
% However. we show that LLMs cannot currently reason about complex spatial relationships like multi-way directional relations and cyclic order relations. %, and relations over complex forms of geospatial data like regions.
%
% This paper presents the position that further work is needed before LLMs can infer implicit spatial information that they were not explicitly exposed to during training.
%
% To support this position, we discuss the challenges associated with spatial reasoning, including the variety of modalities and scales of geodata.
%
% Finally, we present a vision for the future of neural spatial reasoning and suggest several avenues of research to advance current LLM research towards achieving this vision, including devising new embedding methods and developing intuitive self-supervised training objectives for spatial data.