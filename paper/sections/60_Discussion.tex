\section{Discussion}
\label{section:discussion}

%\subsection{Toponym Resolution}

In this section we discuss the significance of the results outlined in the previous section.

\subsection{Metric Relations}

\citeauthor{Bhandari2023} prompt the LLMs to generate names of cities that are ``near'' or ``far'' from a provided reference city.
They show that the resulting cities generated tend to be closer in distance to the reference point when the ``near'' prompt is used, and farther when the ``far'' prompt is used, indicating LLMs associate a smaller metric (distance) to the word `near' than to the word `far'~\cite{Bhandari2023}.
Our results show that these keywords are associated with static distances (i.e. everything `near' a query point was within 1,000 Kilometers of it) even despite prompting that implicitly contained a scale for what `near' should mean (such as a pair of reference cities that were 1,500 Kilometers apart).
All models tested showed this bias towards relying on the qualitative keyword hints in the prompt (`near' or `far') rather than performing quantitative metric reasoning to retrieve places the correct distance to the query point.
The neutral prompt that contained no keyword hint did not show a bias towards too large or small distances, but the spread indicates that the places retrieved were not very close to the correct distance (often off by a thousand or more Kilometers).


\subsection{Directional Relations}
We observe a large discrepancy in reasoning ability between pairwise (two-way) and three-way directional relations, which indicates a fundamental lack of directional spatial reasoning ability in current LLMs.
It is highly likely that popular cities are written about repeatedly in the vast training data LLMs are exposed to.
As a result, we would expect LLMs to memorize many facts about these cities, including potentially where one is located with respect to another, if that was explicitly stated in the data.
However, it is much less likely that the relative locations of three cities with respect to each other appears explicitly in the training data.
Hence, we believe the poor performance across most of the three-way directional relations we tested indicates a lack of the model's ability to infer implicit spatial relationships that it did not learn directly from training.
We discuss ways complex spatial relations can be encoded and provided explicitly to models at training time in section \ref{section:future}.


\subsection{Topological Relations}
We observe poor model performance across several topological relation questions, including the `intersect', `partially overlap', and `within' predicates.
We further find that topological relations between line entities induce especially poor performance when compared to point and region entities.
We hypothesize that the popularity and therefore internet prevalence of many point entities (such as cities) and region entities (such as lakes, states, etc.) is high, increasing the chances that their spatial relationships have been explicitly found in a given LLM's training data.


\subsection{Order Relations}
We observe that model performance on tasks pertaining to order relations is particularly poor.
Order relations are the least commonly used of the four main spatial relations that are common to tasks like spatial pattern matching.
The key qualitative terms `clockwise' and `counterclockwise' that indicate the cyclic order of spatial entities are also not commonly used in language about cities, towns, and other geospatial point entities.
However, order relations represent a clear form of spatial reasoning that can be applied to geospatial data.
Further work could be done to determine if exposure to more context about order relations increases model performance on these tasks.