\section{Related Work}
\label{section:related}
\normalsize

Many recent works have explored the abilities and limitations of LLMs for performing various reasoning tasks, from math word problems~\cite{Gao2023, Badaro2023} to place name resolution \cite{Mai2023}.
In this section we summarize the recent work investigating the degree to which LLMs can reason spatially.
We begin by describing recent vision and position papers on the subject, and then discuss specific advances in embedding methods and other techniques proposed to enable LLMs to ingest and reason over spatial data.


\subsection{Spatial LLMs and Geo Foundation Models}
Two recent vision papers suggest that LLMs show promise for use as spatial databases, where the LLM performs spatial reasoning given natural language prompts~\cite{Bhandari2023, Qi2023}.
\citeauthor{Bhandari2023} and \citeauthor{Qi2023} support their visions with experiments prompting LLMs for geocoordinates of popular cities, with results showing promisingly accurate coordinates for most of the cities tested.
\citeauthor{Bhandari2023} further prompt the LLMs to generate names of cities that are ``near'' or ``far'' from a provided reference city.
They show that the resulting cities generated tend to be closer in distance to the reference point when the ``near'' prompt is used, and farther when the ``far'' prompt is used, indicating LLMs are capable of basic spatial reasoning in the form of understanding relative metric (distance) relations.

This paper presents a similar position, that LLMs have potential to perform spatial reasoning, but our experiments show that much more work is needed before this vision can be realized.
We show that LLMs currently cannot handle many of the intricacies of spatial reasoning beyond the simple pairwise directional relationships between locations tested by \citeauthor{Bhandari2023} and \citeauthor{Qi2023}.

\citeauthor{Mai2023} present a vision of a geo foundation model pre-trained on different modalities of data, aligning their representations based on location information.
We similarly envisage a geo foundation model that can handle many input modalities, but we identify challenges associated with designing embeddings, model architectures, and self-supervised tasks that must first be addressed for individual typers of geodata, before they can be combined in a multimodal geo foundation model.
%\cite{Mai2023} - focuses on need for multimodal and claims some text based geo tasks like toponym recognition are already well-solved by existing LLMs.

Other vision papers highlight the challenges and opportunities associated with combining structured and unstructured geodata to create a geo foundation model, but they do not propose any concrete steps or ideas to achieve such a goal~\cite{Xie2023, Tan2023}



\subsection{Large Language Model Adaptations for Geodata}
A few embedding methods and model architectures have been proposed to enable LLMs to handle some types of geospatial data.

\subsubsection{Embedding Methods}
For trajectories of geocoordinates, embeddings are ... ~\cite{Hu2023}.

For textual georeferences, SpaBERT designs a pre-training task using spatial coordinate embeddings (based on latitude and longitude) corresponding to textual georeferences.
They create pseudosentences containing lists of geoentity references and neighboring entities in the physical world, in increasing order of distance from the original entity~\cite{Li2021}.
Results show that the spatial embedding improves accuracy on downstream tasks of geoentity type prediction and linking geoentities to knowledge graphs.

For modeling complex n-way relationships similar to those needed for tasks like spatial pattern matching, graphs are typically used~\cite{Folkers2000, Chen2019, Fang2019, Osul2023b}.
To train neural models like Graph Neural Networks (GNNs) on graph-encoded data, node-level and edge-level embeddings are common~\cite{Bai2019,Krlevza2016,Liu2020Neural}. \nrscomment{check those papers actually use those embedding types}
%
\nrscomment{find and cite community and graph level embeddings}

For structured tabular data, ... surveys and benchmarks saying tabular transformers are still an open problem:\cite{Cong2023, Badaro2023}
\cite{Iida2021, Somepalli2022, Seng2022, Yin2020, Herzig2020}

\subsubsection{Model Architectures}
For RSI, spatial heterogeneity prevents the standard vision methods from working out of the box. 
\cite{Xie2021} adapts the model architecture through a series of statistical tests to address the different spatial distributions present in the data.
\nrscomment{can we handle it in the embeddings instead?}

\nrscomment{other related work that proposes novel architectures?}


% \subsection{NL to Spatial Query}
%     NALSpatial: \cite{Liu2023}


% \subsection{Testing LLM Spatial Reasoning}
%     \cite{Bhandari2023} shows some degree of near/far but not true complex spatial reasoning
%     MaaSDB: \cite{Qi2023} shows some ability to do pairwise directional relations for well-known cities

% \subsection{Large Language Models as Databases}
%     \paragraph{As generic DBs}
%         \cite{Tan2023}
        
%         James Thorne, Majid Yazdani, Marzieh Saeidi, Fabrizio Silvestri, Sebastian Riedel, and Alon Halevy. 2021. From Natural Language Processing to Neural Databases. PVLDB (2021)
        
%         \cite{Trappolini2023}
        
%     \paragraph{As spatial DBs}
%         Ref ideas of MaaSDB