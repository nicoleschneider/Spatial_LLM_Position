
Recent work has demonstrated that large language models (LLMs) have some level of ``spatial awareness'' in the form of knowledge about geocoordinates, directional relationships between major cities, and relative distances between cities.
%
However. we show that LLMs cannot currently reason about complex spatial relationships like n-way directional relations, topological relations, and relations over complex forms of geospatial data like lines and regions.
%
This paper presents the position that new techniques are needed to enable LLMs to reason about spatial information.
%
To support this position, we discuss the challenges associated with spatial reasoning, including the variety in structured and unstructured modalities of geodata, the concept of spatial heterogeneity, and the need for proper embedding methods to encode some types of geodata.
%
We present a vision for the future of neural spatial reasoning and provide several avenues to advance current LLM research towards achieving this vision.