\section{Introduction}

\label{section:introduction}

With the advent of large language models (LLMs), many recent works have explored what kinds of world knowledge and reasoning capabilities LLMs inherit from their vast training data~\cite{Mai2023, Bhandari2023, Qi2023}.
%
LLMs have been remarkably successful at 

\nrscomment{blah and blah} 
tasks, opening up 

\nrscomment{blah} 
possibilities.
%
However, some reasoning tasks, like spatial reasoning, remain a challenge.
%
\nrscomment{motivate why spatial reasoning is important for LLMs, whats the main use case}
%
Work investigating the spatial reasoning ability of LLMs has demonstrated that LLMs have some basic level of ``spatial awareness'' in the form of knowledge about geocoordinates, directional relationships between major cities, and relative distances between cities~\cite{Bhandari2023, Qi2023}.
However, LLMs are still a long way from being able to infer implicit spatial knowledge from geospatial information, which can come in a variety of formats.


% complex entities and relations
LLMs currently struggle to perform complex spatial reasoning, especially about
%
\textit{\textbf{(i)}} Line and region data,
\textit{\textbf{(ii)}} Spatial relations between more than two spatial objects, and 
\textit{\textbf{(iii)}} Non-directional spatial relation types, like topological or cyclic relations.
%
In our experiments, we found that... \nrscomment{describe details of failure cases found in experiments}
%
In our discussion of these findings, we highlight several specific challenges that need to be solved before LLMs can perform sufficiently complex spatial reasoning to support \nrscomment{application use case}.


The overarching challenge with developing a spatially-aware LLM is that LLMs cannot directly handle many of the formats that geospatial data comes in.
Geospatial data can be organized in structured tables, geocoordinates or trajectories of geocoordinates, remote sensing imagery (RSI), unstructured text containing geoentity references, and graph-encoded data describing dense spatial relations between locations.
%
Many of these data formats require specialized embedding techniques beyond those typical of textual or image data.


% 1. tabular challenges bleed over
Structured tables of geospatial data present a particular challenge, since applying LLMs to tabular data generally remains an open problem~\cite{Gao2023,Cong2023}.
The main challenge is that the standard self-supervised masked token prediction task that is used to train LLMs is incompatible with structured tabular data~\cite{Tan2023, Qi2023}.
In addition, unlike words, table values can be continuous and have vastly different meaning depending on which attribute column they appear in~\cite{Qi2023}.


% 2. spatial heterogeneity
Even data types that neural models typically handle well, like images, present a challenge when they capture complex spatial information.
%
RSI contains spatial data that typically violates the independent and identically distributed (i.i.d.) assumption of neural models, with different spatial regions being generated by different processes, such as land covered by different types of crops and managed by different agricultural practices, that are rarely present in the features. 
This spatial heterogeneity must be accounted for, either by training different models for each distinct spatial region~\cite{Gupta2021}, which is computationally inefficient, or by a specialized model architecture that follows the the spatial data distribution~\cite{Xie2021b}.


% 3. new embedding types needed
For other forms of data, like trajectories of geocoordinates, the inputs are mostly numerical and differ significantly from the kind of natural language text LLMs typically see during pre-training.
In these cases, custom embedding schemes must be designed for these forms of data~\cite{Hu2023}.
%
\nrscomment{describe trajectory embeddings of Hu2023 and explain limitations}
%

For textual georeferences in natural language text, some work has already been done creating spatial coordinate embeddings by binning and vectorizing the corresponding latitude and longitude values of the georeferences~\cite{Li2021}.
However, there remains a need for intuitive self-supervised tasks that will allow LLMs to learn the context for these coordinate embeddings.
%

% 4. multimodal
Moreover, there are no well-studied methods for combining multiple modalities of spatial data for input into neural models.

\nrscomment{say something about state of multimodal learning} \cite{Trappolini2023}.


This paper presents the position that LLMs have the potential to perform spatial reasoning, but that the aforementioned challenges need to be addressed before this vision can be realized.
%
To begin to address these challenges, we first envision the development of novel embedding methods and self-supervised training objectives for various types of geodata.
%
For complex, multi-way spatial relations, one avenue is encoding the data in a graph and leveraging node-level, edge-level, and community-level embeddings to provide adequate context for learning.
For structured tabular geodata, embedding techniques like row-level and column-level embeddings that are being investigated for non-spatial tabular transformers may provide a good starting point, with additional work needed to adequately handle geographic entities that would otherwise be treated as out-of-dictionary tokens.
For RSI data, standard vision embeddings and convolution architectures are applicable, but the model design or embedding schema must be adapted to account for the spatial heterogeneity of the underlying data.
%
As we describe in our proposed road-map, once embedding methods have been well-established for geodata, it will then be possible to leverage recent and future work in multimodal learning to combine a variety of input modalities, to train a geo foundation model.
%
We envision such a foundation model would be useful in \nrscomment{application use case}.

The rest of this paper presents the necessary background on spatial reasoning in section \ref{section:background}, followed by a set of experiments designed to probe the spatial reasoning limitations of current LLMs in section \ref{section:experiments}.
Then in section \ref{section:results} we discuss the results of the experiments and in section \ref{section:proposal} we propose solutions for overcoming the limitations we highlight.
Finally, we describe the related spatial LLM work in section \ref{section:related} before concluding in section \ref{section:conclusion}. 
%-------------------------------

% ARGUMENT FOR NEURALDB TYPE RETRIEVER:
% LLM cannot naturally do spatial reasoning, it can just memorize some facts - possibly a lot of spatial facts, but there is no generalizeability there in the way that when it learns language it learns the grammar and rules of the language that can be applied more generally.

% General spatial facts about the world can't be guessed if the training data isn't there. 
% They can be added to a DB, which is easier than retraining a model. 
% The model should act as the retriever.

% By training on all the history books, an LLM can learn everything humans know about history.
% How does it learn the implicit facts that can be inferred from other facts? Does it?

% By training on all the spatial data (of which there's much more?) it can't learn all the n-way implicit relationships between all locations - that is not a language task. 
% At best it can narrow down and issue a query to a tool that can do spatial reasoning.
