\section{Introduction}

\label{section:introduction}

With the recent advent of large language models (LLMs), many works have explored what kinds of world knowledge and reasoning capabilities LLMs inherit from their vast training data~\cite{Mai2023, Bhandari2023, Qi2023}.
%
\nrscomment{motivate why spatial reasoning is important for LLMs}
%
Work investigating the spatial reasoning ability of LLMs has demonstrated that LLMs have some level of ``spatial awareness'' in the form of knowledge about geocoordinates, directional relationships between major cities, and relative distances between cities~\cite{Bhandari2023, Qi2023}.
However, LLMs are still a long way from being able to infer implicit spatial knowledge from the geospatial information they are exposed to during training on natural language text.


% 1. complex entities and relations
Specifically, LLMs cannot reason correctly about complex spatial relationships, including
%
\textit{\textbf{(i)}} Line and region data,
\textit{\textbf{(ii)}} N-way spatial relations between more than two spatial objects at a time, and 
\textit{\textbf{(iii)}} Various spatial relation types, like topological or cyclic relations.
%
In our experiments, we found that... \nrscomment{describe details of failure cases found in experiments}


% 2. various data types
Further, LLMs cannot directly handle the various formats that geospatial data comes in.
Geospatial data can be organized in structured tables, geocoordinates or trajectories of geocoordinates, remote sensing imagery (RSI), natural text containing geoentity references, and graph-encoded data describing objects and their spatial relations to each other.
%
Many of these data formats require embedding methods that differ from the techniques used for typical textual or image data, and there are no well-studied methods for incorporating multiple modalities of spatial data into neural models ... \nrscomment{say something about state of multimodal learning} \cite{Trappolini2023}.


% 3. tabular challenges bleed over
Structured tables of geospatial data present a particular challenge, since applying LLMs to tabular data generally remains an open problem~\cite{Gao2023,Cong2023}.
The main challenge is that the standard self-supervised masked token prediction task that is used to train LLMs is incompatible with structured tabular data~\cite{Tan2023, Qi2023}.
In addition, unlike words, table values can be continuous and have vastly different meaning depending on which attribute column they appear in~\cite{Qi2023}.


% 4. spatial heterogeneity
Even data types that neural models typically handle well, like images, present a challenge when they capture complex spatial information.
%
RSI contains spatial data that typically violates the independent and identically distributed (i.i.d.) assumption of neural models, with different spatial regions being generated by different processes, such as land covered by different types of crops and managed by different agricultural practices, that are rarely present in the features. 
This spatial heterogeneity must be accounted for, either by training different models for each distinct spatial region~\cite{Gupta2021}, which is computationally inefficient, or by carefully constructing the model architecture to follow the the spatial data distribution~\cite{Xie2021b}.


% 5. new embedding types needed
For other forms of data, like trajectories of geocoordinates, the inputs are mostly numerical and differ significantly from the kind of natural language text LLMs typically see during pre-training.
In these cases, custom embedding schemes must be designed for these forms of data~\cite{Hu2023}.
%
\nrscomment{describe trajectory embeddings of Hu2023 and explain limitations}
%

For textual georeferences in natural language text, spatial coordinate embeddings can be created by binning and vectorizing the corresponding latitude and longitude values of the georeferences~\cite{Li2021}.
However, there remains a need for intuitive self-supervised tasks that would allow LLMs to learn the context for these coordinate embeddings.
%


To address these challenges, we first envision the development of novel embedding methods and self-supervised training objectives for various types of geodata.
This may include embedding complex spatial relations using graphs and leveraging node-level, edge-level, and community-level embeddings to provide adequate context for learning.
For structured tabular geodata, the embedding techniques like row and column embeddings that are being investigated to advance non-spatial tabular transformers may provide a good starting point, with additional work needed to adequately handle geo entities that would otherwise be treated as out-of-dictionary tokens.
For RSI data, standard vision embeddings and convolution architectures can provide a starting point, but the model design or embedding schema must be adapted to account for spatial heterogeneity of the underlying data.
%
As we describe, once embedding methods have been well-established for geodata, it will then be possible to leverage work in multimodal learning to combine a variety of input modalities, to train a geo foundation model.

The rest of this paper presents the necessary background on spatial reasoning in section \ref{section:background}, followed by a set of experiments designed to probe the spatial reasoning limitations of current LLMs in section \ref{section:experiments}.
Then in section \ref{section:results} we discuss the results of the experiments and in section \ref{section:proposal} we propose solutions for overcoming the limitations we exposed.
Finally, we describe the related spatial foundation model work in section \ref{section:related} before concluding in section \ref{section:conclusion}. 
%-------------------------------

% ARGUMENT FOR NEURALDB TYPE RETRIEVER:
% LLM cannot naturally do spatial reasoning, it can just memorize some facts - possibly a lot of spatial facts, but there is no generalizeability there in the way that when it learns language it learns the grammar and rules of the language that can be applied more generally.

% General spatial facts about the world can't be guessed if the training data isn't there. 
% They can be added to a DB, which is easier than retraining a model. 
% The model should act as the retriever.

% By training on all the history books, an LLM can learn everything humans know about history.
% How does it learn the implicit facts that can be inferred from other facts? Does it?

% By training on all the spatial data (of which there's much more?) it can't learn all the n-way implicit relationships between all locations - that is not a language task. 
% At best it can narrow down and issue a query to a tool that can do spatial reasoning.
