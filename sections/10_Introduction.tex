\section{Introduction}

\label{section:introduction}

With the recent advent of large language models (LLMs), many works have explored what kinds of world knowledge and reasoning capabilities LLMs inherit from their vast training data~\cite{Mai2023, Bhandari2023, Qi2023}.
Work exploring the spatial reasoning ability of LLMs has demonstrated that LLMs have some level of ``spatial awareness'' in the form of knowledge about geocoordinates, directional relationships between major cities, and relative distances between cities~\cite{Bhandari2023, Qi2023}.
However, LLMs are still a long way from being able to infer implicit spatial knowledge from the geospatial information they are coincidentally exposed to while training on natural language text.


% 1. complex entities and relations
They do not handle complex n-way relations, relation types besides directional and metric (like topological and cyclic relations), and line and region data types.
\nrscomment{describe details of failure cases found in experiments}


% 2. various data types
They cannot handle various types of geospatial data as input.
Geospatial data come in the form of structured tables, geocoordinates or trajectories of geocoordinates, remote sensing imagery (RSI), natural text containing geoentity references, and graph-encoded data describing objects and their spatial relations to each other.
%
There are no well-studied methods for incorporating these modalities of spatial data into neural models ... \nrscomment{say something about state of multimodal learning} \cite{Trappolini2023}.


% 3. tabular challenges bleed over
Structured tables of geospatial data present a particular challenge, since applying LLMs to tabular data generally remains an open problem. \nrscomment{cite some}
The main challenge is that the standard self-supervised masked token prediction task that is used to train LLMs is incompatible with structured tabular data. \cite{Tan2023, Qi2023}
In addition, unlike words, table vales can be continuous and have vastly different meaning depending on attribute column they appear in~\cite{Qi2023}.


% 4. spatial heterogeneity
Even data types that neural models typically handle well, like images, present a challenge when they capture complex spatial information.
%
RSI captures data that typically violates the independent and identically distributed (i.i.d.) assumption of neural models, with different spatial regions being generated by different processes, such as land covered by different types of crops~\cite{Xie2021}. 
This spatial heterogeneity must be accounted for, either by training different models for each distinct spatial region, which is computationally inefficient, or by carefully constructing the model architecture to follow the the spatial data distribution~\cite{Gupta2021}.


% 5. new embedding types needed
For other forms of data, like trajectories of geocoordinates, the inputs are very different from the natural language text LLMs see during pre-training and so appropriate embedding schemes must be designed for these forms of data~\cite{Hu2023}.
%
Work towards designing spatial embeddings has been limited thus far.
%
\nrscomment{describe trajectory embeddings of Hu2023}
%
Spatial coordinate embeddings can be created for textual georeferences by binning and vectorizing their corresponding latitude and longitude values~\cite{Li2021}.
However, there remains a need for intuitive self-supervised tasks that would allow LLMs to learn the context for these embeddings.
%


To address these challenges, we first envision the development of novel embedding methods and self-supervised training objectives for various types of geodata.
This may include embedding complex spatial relations using graphs and leveraging node-level, edge-level, and community-level embeddings to provide adequate context for learning.
For structured tabular geodata, the embedding techniques like row and column embeddings that are being investigated to advance generic tabular transformers may provide a good starting point, with additional work needed to adequately handle geo entity tokens that would otherwise be treated as out-of-dictionary tokens.
For RSI data, standard vision embeddings and convolution architectures can provide a starting point, but the model design or embedding schema must be adapted to account for spatial heterogeneity.
%
As we describe, once embedding methods have been well-established for geodata, it will then be possible to leverage work in multimodal learning to combine a variety of input modalities, to train a geo foundation model.


%-------------------------------

% ARGUMENT FOR NEURALDB TYPE RETRIEVER:
% LLM cannot naturally do spatial reasoning, it can just memorize some facts - possibly a lot of spatial facts, but there is no generalizeability there in the way that when it learns language it learns the grammar and rules of the language that can be applied more generally.

% General spatial facts about the world can't be guessed if the training data isn't there. 
% They can be added to a DB, which is easier than retraining a model. 
% The model should act as the retriever.

% By training on all the history books, an LLM can learn everything humans know about history.
% How does it learn the implicit facts that can be inferred from other facts? Does it?

% By training on all the spatial data (of which there's much more?) it can't learn all the n-way implicit relationships between all locations - that is not a language task. 
% At best it can narrow down and issue a query to a tool that can do spatial reasoning.
